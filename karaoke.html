<!DOCTYPE html>
<html>
<head>
  <title>Karaoke</title>
  <style>
    /* スタイルの設定 */
    #container {
      text-align: center;
      padding-top: 50px;
    }

    #upload-btn {
      display: none;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>Karaoke</h1>
    <input type="file" id="upload-btn" accept="audio/mp4">
    <button onclick="chooseFile()">Choose File</button>
    <br>
    <br>
    <button onclick="startKaraoke()">Start Karaoke</button>
    <br>
    <br>
    <div id="score"></div>
    <br>
    <br>
    <video id="video-player" width="640" height="480" controls></video>
  </div>

  <script>
    var audioContext = new (window.AudioContext || window.webkitAudioContext)();
    var mediaRecorder;
    var chunks = [];
    var stream;

    function chooseFile() {
      document.getElementById('upload-btn').click();
    }

    function startKaraoke() {
      var audioPlayer = new Audio();
      audioPlayer.src = URL.createObjectURL(document.getElementById('upload-btn').files[0]);

      // 音声再生用の処理
      audioPlayer.oncanplaythrough = function () {
        audioContext.resume().then(function () {
          audioPlayer.play();
          startMicrophone();
        });
      };

      function startMicrophone() {
        if (!audioContext.audioWorklet) {
          console.error('AudioWorkletNode is not supported in this browser.');
          return;
        }

        audioContext.audioWorklet.addModule('script-processor.js')
          .then(function () {
            var audioProcessor = new AudioWorkletNode(audioContext, 'script-processor');
            var audioInput = audioContext.createMediaStreamSource(stream);
            var audioOutput = audioContext.createMediaStreamDestination();
            var audioStream = audioOutput.stream;

            audioInput.connect(audioProcessor);
            audioProcessor.connect(audioOutput);

            // 音声の拡大とエコー処理はオーディオワークレットで行われるため、ここでは不要です。

            // オーディオ要素に出力ストリームを接続して再生する
            var audioPlayer = new Audio();
            audioPlayer.srcObject = audioStream;
            audioPlayer.play();
          })
          .catch(function (err) {
            console.error(err);
          });
      }

      // デバッグ情報の出力
      console.log('Audio Context: ', audioContext.state);
      console.log('Audio Player: ', audioPlayer.readyState);
      console.log('Microphone Stream: ', stream);
    }


  
  // videoPlayer要素の再生を開始
  // 以下の部分は省略...
            // ここで音声データの数値化処理を行う
            // 音声データの数値化処理
function processAudioData(inputData) {
  var sum = 0;
  for (var i = 0; i < inputData.length; i++) {
    sum += Math.abs(inputData[i]);
  }
  var average = sum / inputData.length;
  // 例: 数値化されたデータを利用して何らかの処理を行う

  return average;
}

// 点数の計算
function calculateScore(songData, voiceData) {
  // 例: 曲のデータと歌声のデータを比較して点数を計算する
  var score = 0;
  for (var i = 0; i < songData.length; i++) {
    if (Math.abs(songData[i] - voiceData[i]) <= threshold) {
      score++;
    }
  }
  return score;
}

// グローバル変数として曲データを保持する配列
var songData = [];

// マイクからの音声処理
audioProcessor.onaudioprocess = function (e) {
  var inputData = e.inputBuffer.getChannelData(0);
  var voiceData = processAudioData(inputData);
  var score = calculateScore(songData, voiceData);

  // ポイントの加算などの処理

  // 得点を表示する
  document.getElementById('score').textContent = 'Score: ' + score;
};
  </script>
</body>
</html>
